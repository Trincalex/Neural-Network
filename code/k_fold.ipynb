{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ea627e4-3f8d-4b0c-8510-f11be4958ea3",
   "metadata": {},
   "source": [
    "### k_fold.ipynb\n",
    "- Alessandro Trincone\n",
    "- Mario Gabriele Carofano\n",
    "\n",
    "> ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6fb490-c50e-48dd-a7c4-a785d3966e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import auxfunc\n",
    "import constants\n",
    "from artificial_neural_network import NeuralNetwork\n",
    "from training_report import TrainingReport\n",
    "from training_params import TrainingParams\n",
    "import dataset_functions as df\n",
    "import plot_functions as pf\n",
    "\n",
    "import numpy as np\n",
    "import pprint\n",
    "import time\n",
    "from datetime import datetime\n",
    "import copy\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440fcec9-1f4f-47c5-83fd-5565fa93ae53",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6912001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(\n",
    "        out_directory : str,\n",
    "        Xtrain : list[np.ndarray],\n",
    "        Ytrain : list[np.ndarray],\n",
    "        k : int = constants.DEFAULT_K_FOLD_VALUE,\n",
    "        l_sizes : list[int] = constants.DEFAULT_HIDDEN_LAYER_NEURONS,\n",
    "        params : TrainingParams = None\n",
    ") -> tuple[float, float, float, float]:\n",
    "    \n",
    "    \"\"\"\n",
    "        E' una tecnica di validazione che utilizza una parte indipendente del training set per la fase di validazione. Si utilizza per la selezione degli iper-parametri che restituiscono il minor errore di validazione sull'addestramento del modello.\n",
    "\n",
    "        Parameters:\n",
    "        -   out_directory : la directory di output dove salvare i grafici della k-fold cross validation.\n",
    "        -   Xtrain : la matrice di esempi da classificare.\n",
    "        -   Ytrain : la matrice di etichette corrispondenti agli esempi (ground truth).\n",
    "        -   k : e' un numero intero che indica in quante fold dividere il training set.\n",
    "        -   l_sizes : e' una lista contenente le dimensioni di uno o piu' hidden layer e dell'output layer della rete neurale.\n",
    "        -   params : e' un oggetto della classe TrainingParams che contiene alcuni iperparametri per la fase di addestramento della rete neurale.\n",
    "\n",
    "        Returns:\n",
    "        -   err_mean : la media dei valori di errore di validazione su tutti i modelli addestrati.\n",
    "        -   err_std : la deviazione standard dei valori di errore di validazione su tutti i modelli addestrati.\n",
    "        -   acc_mean : la media delle percentuali di accuracy di validazione su tutti i modelli addestrati.\n",
    "        -   acc_std : la deviazione standard delle percentuali di accuracy di validazione su tutti i modelli addestrati.\n",
    "    \"\"\"\n",
    "\n",
    "    fold_reports = []\n",
    "\n",
    "    Xfolds, Yfolds = df.split_dataset(Xtrain, Ytrain, k)\n",
    "\n",
    "    for i in range(k):\n",
    "\n",
    "        print(f\"\\nFold {i+1} di {k}\")\n",
    "\n",
    "        # Tutti gli altri parametri di NeuralNetwork sono inizializzati con i valori default\n",
    "        net = NeuralNetwork(l_sizes=l_sizes)\n",
    "\n",
    "        training_fold = np.concatenate([fold for j, fold in enumerate(Xfolds) if j != i])\n",
    "        training_labels = np.concatenate([fold for j, fold in enumerate(Yfolds) if j != i])\n",
    "        validation_fold = Xfolds[i]\n",
    "        validation_labels = Yfolds[i]\n",
    "\n",
    "        history_report = net.train(\n",
    "            training_fold, training_labels,\n",
    "            validation_fold, validation_labels,\n",
    "            params\n",
    "        )\n",
    "\n",
    "        accs = [r.validation_accuracy for r in history_report]\n",
    "        errs = [r.validation_error for r in history_report]\n",
    "\n",
    "        fold_reports.append({\n",
    "            \"Fold\"      : i+1,\n",
    "            \"Report\"    : copy.deepcopy(net.training_report),\n",
    "            \"E_mean\"    : np.mean(errs),\n",
    "            \"E_std\"     : np.std(errs),\n",
    "            \"E_min\"     : np.min(errs),\n",
    "            \"E_max\"     : np.max(errs),\n",
    "            \"A_mean\"    : np.mean(accs),\n",
    "            \"A_std\"     : np.std(accs),\n",
    "            \"A_min\"     : np.min(accs),\n",
    "            \"A_max\"     : np.max(accs)\n",
    "        })\n",
    "\n",
    "        del net\n",
    "        del training_fold, training_labels\n",
    "        del validation_fold, validation_labels\n",
    "        gc.collect()\n",
    "\n",
    "        if constants.DEBUG_MODE:\n",
    "            break\n",
    "\n",
    "    # end for i\n",
    "\n",
    "    # Disegno di un line plot con le percentuali di accuracy, media e deviazione standard su tutte le fold.\n",
    "    acc_mean, acc_std = pf.plot_k_fold_accuracy_scores(out_directory, fold_reports)\n",
    "\n",
    "    # Disegno di un line plot con i valori di errore, media e deviazione standard su tutte le fold.\n",
    "    err_mean, err_std = pf.plot_k_fold_error_scores(out_directory, fold_reports)\n",
    "\n",
    "    return err_mean, err_std, acc_mean, acc_std\n",
    "\n",
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a27525a",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd504f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_cv(\n",
    "        out_directory : str,\n",
    "        Xtrain : list[np.ndarray],\n",
    "        Ytrain : list[np.ndarray],\n",
    "        k : int = constants.DEFAULT_K_FOLD_VALUE,\n",
    "):\n",
    "    \n",
    "    \"\"\"\n",
    "        ...\n",
    "\n",
    "        Parameters:\n",
    "        -   out_directory : la directory di output dove salvare i grafici della k-fold cross validation.\n",
    "        -   Xtrain : la matrice di esempi da classificare.\n",
    "        -   Ytrain : la matrice di etichette corrispondenti agli esempi (ground truth).\n",
    "        -   k : e' un numero intero che indica in quante fold dividere il training set.\n",
    "\n",
    "        Returns:\n",
    "        -   ... : ...\n",
    "    \"\"\"\n",
    "\n",
    "    # Il valore tipico per \"eta minus\" e' compreso tra 0.5 e 0.9.\n",
    "    # Valori più vicini a 0.5 riducono il passo di aggiornamento in modo più aggressivo, migliorando la stabilita' ma potenzialmente rallentando la convergenza.\n",
    "    # Valori più vicini a 0.9 sono meno aggressivi, permettendo una convergenza più rapida ma con il rischio di instabilita'.\n",
    "    eta_minus_values = [0.5, 0.7, 0.9]\n",
    "\n",
    "    # Il valore tipico per \"eta plus\" e' compreso tra 1.2 e 1.5.\n",
    "    # Valori più vicini a 1.2 incrementano il passo di aggiornamento in modo più moderato, migliorando la stabilita' e riducendo il rischio di oscillazioni.\n",
    "    # Valori più vicini a 1.5 incrementano il passo di aggiornamento in modo più aggressivo, accelerando la convergenza ma aumentando il rischio di instabilita'.\n",
    "    eta_plus_values = [1.2, 1.3, 1.5]\n",
    "\n",
    "    # Per problemi di classificazione (es. riconoscimento di cifre scritte a mano), un intervallo comune per il numero di neuroni è da 10 a 100 per uno o due hidden layer.\n",
    "    # Tuttavia, siccome l'input ha alta dimensionalita', potrebbe essere necessario aumentare il numero di neuroni per catturare le caratteristiche importanti. Ad esempio, per immagini 28x28, l'hidden layer puo' avere un numero di neuroni compreso tra 128 e 512.\n",
    "    hidden_layer_values = [128, 256, 512]\n",
    "\n",
    "    # Si inizializza un \"DataFrame\" per la raccolta delle metriche di valutazione.\n",
    "    stats = pd.DataFrame({\n",
    "        \"Eta minus\"     : [],\n",
    "        \"Eta plus\"      : [],\n",
    "        \"Hidden layer\"  : [],\n",
    "        \"Mean error\"    : [],\n",
    "        \"Std error\"     : [],\n",
    "        \"Mean accuracy\" : [],\n",
    "        \"Std accuracy\"  : []\n",
    "    })\n",
    "\n",
    "    # Si calcolano tutte le possibili combinazioni di iper-parametri.\n",
    "    combs = [\n",
    "        (x, y, z)\n",
    "        for x in eta_minus_values\n",
    "        for y in eta_plus_values\n",
    "        for z in hidden_layer_values\n",
    "    ]\n",
    "\n",
    "    # Questo ciclo \"for\" esamina tutte le possibili combinazioni di iper-parametri.\n",
    "    for i, (em, ep, hl) in enumerate(combs):\n",
    "\n",
    "        print(f\"Combinazione {i+1}:\\n\\tEta minus = {em},\\n\\tEta plus = {ep},\\n\\tHidden layer = {hl}\\n\")\n",
    "\n",
    "        # Si applica la tecnica di validazione \"K-fold cross validation\" per valutare la combinazione di iper-parametri corrente. \n",
    "        # err_mean, err_std, acc_mean, acc_std = k_fold_cross_validation(\n",
    "        #     out_directory,\n",
    "        #     Xtrain, Ytrain, k,\n",
    "        #     [hl, 10],\n",
    "        #     params=TrainingParams(\n",
    "        #         epochs=2,\n",
    "        #         eta_minus=em,\n",
    "        #         eta_plus=ep\n",
    "        #     )\n",
    "        # )\n",
    "        err_mean, err_std, acc_mean, acc_std = (0,0,0,0)\n",
    "\n",
    "        # Si crea un dizionario per raccogliere tutte le metriche di valutazione riguardo la rete appena addestrata sulla combinazione di iperparametri corrente.\n",
    "        new_row = {\n",
    "            \"Eta minus\"     : em,\n",
    "            \"Eta plus\"      : ep,\n",
    "            \"Hidden layer\"  : int(hl),\n",
    "            \"Mean error\"    : err_mean,\n",
    "            \"Std error\"     : err_std,\n",
    "            \"Mean accuracy\" : acc_mean,\n",
    "            \"Std accuracy\"  : acc_std\n",
    "        }\n",
    "\n",
    "        # Si aggiunge il dizionario come nuova riga alla tabella generale.\n",
    "        stats = pd.concat([stats, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "        # Si ripristina l'indice per mantenere l'ordinamento cronologico.\n",
    "        stats = stats.reset_index(drop=True)\n",
    "    \n",
    "    # end for i, (em, ep, hl)\n",
    "\n",
    "    # Si visualizzano le statistiche raccolte in una tabella.\n",
    "    display(stats)\n",
    "\n",
    "    # Infine, si salva la tabella in un file \".csv\".\n",
    "    os.makedirs(out_directory, exist_ok=True)\n",
    "    stats.to_csv(out_directory + 'stats.csv', index=False)\n",
    "\n",
    "# end\n",
    "\n",
    "# RIFERIMENTI\n",
    "# https://saturncloud.io/blog/how-to-insert-a-row-to-pandas-dataframe/\n",
    "# https://www.geeksforgeeks.org/display-the-pandas-dataframe-in-table-style/\n",
    "# https://stackoverflow.com/questions/75956209/error-dataframe-object-has-no-attribute-append\n",
    "# https://stackoverflow.com/questions/17006641/single-line-nested-for-loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a984210",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4281dd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search_cv(\n",
    "        out_directory : str,\n",
    "        Xtrain : list[np.ndarray],\n",
    "        Ytrain : list[np.ndarray],\n",
    "        k : int = constants.DEFAULT_K_FOLD_VALUE,\n",
    "        r : int = constants.DEFAULT_RANDOM_COMBINATIONS\n",
    "):\n",
    "    \n",
    "    \"\"\"\n",
    "        ...\n",
    "\n",
    "        Parameters:\n",
    "        -   out_directory : la directory di output dove salvare i grafici della k-fold cross validation.\n",
    "        -   Xtrain : la matrice di esempi da classificare.\n",
    "        -   Ytrain : la matrice di etichette corrispondenti agli esempi (ground truth).\n",
    "        -   k : e' un numero intero che indica in quante fold dividere il training set.\n",
    "        -   r : ...\n",
    "\n",
    "        Returns:\n",
    "        -   ... : ...\n",
    "    \"\"\"\n",
    "\n",
    "    eta_minus_values = [0.5, 0.7, 0.9]\n",
    "    eta_plus_values = [1.2, 1.3, 1.5]\n",
    "    hidden_layer_values = [128, 256, 512]\n",
    "\n",
    "    stats = pd.DataFrame({\n",
    "        \"Eta minus\"     : [],\n",
    "        \"Eta plus\"      : [],\n",
    "        \"Hidden layer\"  : [],\n",
    "        \"Mean error\"    : [],\n",
    "        \"Std error\"     : [],\n",
    "        \"Mean accuracy\" : [],\n",
    "        \"Std accuracy\"  : []\n",
    "    })\n",
    "\n",
    "    combs = [\n",
    "        (x, y, z)\n",
    "        for x in eta_minus_values\n",
    "        for y in eta_plus_values\n",
    "        for z in hidden_layer_values\n",
    "    ]\n",
    "\n",
    "    # Si utilizza il metodo \"shuffle\" per riordinare in modo casuale le combinazioni di iper-parametri.\n",
    "    random.shuffle(combs)\n",
    "\n",
    "    # Questo ciclo \"for\" esamina solo le prime \"r\" combinazioni di iper-parametri.\n",
    "    for i in range(r):\n",
    "\n",
    "        em = combs[i][0]\n",
    "        ep = combs[i][1]\n",
    "        hl = combs[i][2]\n",
    "        \n",
    "        print(f\"Combinazione {i+1}:\\n\\tEta minus = {em},\\n\\tEta plus = {ep},\\n\\tHidden layer = {hl}\\n\")\n",
    "\n",
    "        err_mean, err_std, acc_mean, acc_std = k_fold_cross_validation(\n",
    "            out_directory,\n",
    "            Xtrain, Ytrain, k,\n",
    "            [hl, 10],\n",
    "            params=TrainingParams(\n",
    "                epochs=2,\n",
    "                eta_minus=em,\n",
    "                eta_plus=ep\n",
    "            )\n",
    "        )\n",
    "\n",
    "        new_row = {\n",
    "            \"Eta minus\"     : em,\n",
    "            \"Eta plus\"      : ep,\n",
    "            \"Hidden layer\"  : int(hl),\n",
    "            \"Mean error\"    : err_mean,\n",
    "            \"Std error\"     : err_std,\n",
    "            \"Mean accuracy\" : acc_mean,\n",
    "            \"Std accuracy\"  : acc_std\n",
    "        }\n",
    "\n",
    "        stats = pd.concat([stats, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        stats = stats.reset_index(drop=True)\n",
    "\n",
    "    # end for i\n",
    "\n",
    "    display(stats)\n",
    "\n",
    "    os.makedirs(out_directory, exist_ok=True)\n",
    "    stats.to_csv(out_directory + 'stats.csv', index=False)\n",
    "\n",
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8396420f",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7d92aa-1c9d-40d4-890b-ceb361fc1842",
   "metadata": {},
   "outputs": [],
   "source": [
    "idTrain, Xtrain, Ytrain, idTest, Xtest, Ytest = df.loadDataset(constants.COPPIE_TRAINING, constants.COPPIE_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f866b7-7919-4de0-8bd9-e03ae36fa49b",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0917fe04-d798-47be-a3a5-6ed418f7350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_directory = constants.OUTPUT_DIRECTORY + datetime.now().strftime(constants.OUTPUT_DATE_TIME_FORMAT) + \"/\"\n",
    "print(f\"\\nK-fold cross-validation iniziato: {datetime.now().strftime(constants.PRINT_DATE_TIME_FORMAT)}\")\n",
    "start_time = time.time()\n",
    "\n",
    "grid_search_cv(out_directory, Xtrain, Ytrain)\n",
    "random_search_cv(out_directory, Xtrain, Ytrain)\n",
    "\n",
    "end_time = time.time()\n",
    "tot_time = end_time - start_time\n",
    "\n",
    "print(f\"\\nK-fold cross-validation completato: {datetime.now().strftime(constants.PRINT_DATE_TIME_FORMAT)}\")\n",
    "print(f\"Tempo trascorso: {tot_time:.3f} secondi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a068c102",
   "metadata": {},
   "source": [
    "Se si vuole utilizzare una rete già addestrata con i seguenti parametri, iper-parametri e metriche di valutazione: <br>\n",
    "NeuralNetwork( <br>\n",
    "&emsp;depth = 2, <br>\n",
    "&emsp;input_size = 784, <br>\n",
    "&emsp;network_layers = [<br>\n",
    "&emsp;Layer( <br>\n",
    "&emsp;&emsp;size = 64, <br>\n",
    "&emsp;&emsp;act_fun = <function leaky_relu at 0x10791c4c0>, <br>\n",
    "&emsp;&emsp;inputs_size = (12500, 784) <br>\n",
    "&emsp;&emsp;weights_shape = (64, 784), <br>\n",
    "&emsp;&emsp;biases_shape = (64, 1) <br>\n",
    "&emsp;), <br>\n",
    "&emsp;Layer( <br>\n",
    "&emsp;&emsp;size = 10, <br>\n",
    "&emsp;&emsp;act_fun = <function identity at 0x107dda680>, <br>\n",
    "&emsp;&emsp;inputs_size = (12500, 64) <br>\n",
    "&emsp;&emsp;weights_shape = (10, 64), <br>\n",
    "&emsp;&emsp;biases_shape = (10, 1) <br>\n",
    "&emsp;)], <br>\n",
    "&emsp;err_fun = <function cross_entropy_softmax at 0x107dda8c0>, <br>\n",
    "&emsp;training_report = TrainingReport( <br>\n",
    "&emsp;&emsp;num_epochs = 100, <br>\n",
    "&emsp;&emsp;elapsed_time = 184.053 secondi, <br>\n",
    "&emsp;&emsp;training_error = 1.83840, <br>\n",
    "&emsp;&emsp;training_accuracy = 79.22 %, <br>\n",
    "&emsp;&emsp;validation_error = 0.00000 <br>\n",
    "&emsp;&emsp;validation_accuracy = 0.00 % <br>\n",
    "&emsp;) <br>\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037817ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = NeuralNetwork.load_network_from_file(\"../output/2024-06-13_17-31/params.pkl\")\n",
    "# net = NeuralNetwork(\n",
    "#     784, [64, 10],\n",
    "#     l_act_funs=[auxfunc.leaky_relu, auxfunc.identity],\n",
    "#     e_fun=auxfunc.cross_entropy_softmax\n",
    "# )\n",
    "\n",
    "# history_report = net.train(Xtrain, Ytrain, examples=len(Xtrain), rprop=True)\n",
    "# pf.plot_error(out_directory, \"rprop\", [r.training_error for r in history_report])\n",
    "# pf.plot_accuracy(out_directory, \"rprop\", [r.training_accuracy for r in history_report])\n",
    "\n",
    "# print(repr(net))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3ca79d-88eb-4fee-ac0a-d49588514371",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f832b7d8-4cc1-4831-b9b8-baa8b9978c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.test(\n",
    "#     out_directory,\n",
    "#     idTest, Xtest, Ytest,\n",
    "#     plot_mode=constants.PlotTestingMode.ALL\n",
    "# )\n",
    "\n",
    "# net.predict(idTest, Xtest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
