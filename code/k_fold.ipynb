{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ea627e4-3f8d-4b0c-8510-f11be4958ea3",
   "metadata": {},
   "source": [
    "### k_fold.ipynb\n",
    "- Alessandro Trincone\n",
    "- Mario Gabriele Carofano\n",
    "\n",
    "> ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6fb490-c50e-48dd-a7c4-a785d3966e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import auxfunc\n",
    "import constants\n",
    "\n",
    "import numpy as np\n",
    "from artificial_neural_network import NeuralNetwork\n",
    "from training_report import TrainingReport\n",
    "import dataset_functions as df\n",
    "\n",
    "import pprint\n",
    "import time\n",
    "from datetime import datetime\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8396420f",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6912001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(\n",
    "        Xtrain : list[np.ndarray],\n",
    "        Ytrain : list[np.ndarray],\n",
    "        k : int = constants.DEFAULT_K_FOLD_VALUE\n",
    ") -> NeuralNetwork:\n",
    "    \n",
    "    \"\"\"\n",
    "        E' una tecnica di validazione che utilizza una parte indipendente del training set per la fase di validazione. Si utilizza per la selezione del modello che restituisce il minor errore di validazione.\n",
    "\n",
    "        Parameters:\n",
    "        -   Xtrain : la matrice di esempi da classificare.\n",
    "        -   Ytrain : la matrice di etichette corrispondenti agli esempi (ground truth).\n",
    "        -   k : e' un numero intero che indica in quante fold dividere il training set.\n",
    "\n",
    "        Returns:\n",
    "        -   net : la rete neurale che mostra la miglior configurazione di pesi e bias dopo le fasi di addestramento e validazione su tutte le fold del dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    history_report : list[TrainingReport] = []\n",
    "\n",
    "    Xfolds, Yfolds = df.split_dataset(Xtrain, Ytrain, k)\n",
    "\n",
    "    for i in range(k):\n",
    "\n",
    "        print(f\"\\nFold {i+1} di {k}\")\n",
    "\n",
    "        net = NeuralNetwork(\n",
    "            784, 64, 10,\n",
    "            hidden_act_funs=auxfunc.leaky_relu,\n",
    "            output_act_fun=auxfunc.identity,\n",
    "            e_fun=auxfunc.cross_entropy_softmax,\n",
    "            random_init=False\n",
    "        )\n",
    "\n",
    "        training_fold = np.concatenate([fold for j, fold in enumerate(Xfolds) if j != i])\n",
    "        training_labels = np.concatenate([fold for j, fold in enumerate(Yfolds) if j != i])\n",
    "        validation_fold = Xfolds[i]\n",
    "        validation_labels = Yfolds[i]\n",
    "\n",
    "        if i == 0:\n",
    "            best_fold_params = {\n",
    "                \"Fold\"      : i+1,\n",
    "                \"Weights\"   : copy.deepcopy(net.weights),\n",
    "                \"Biases\"    : copy.deepcopy(net.biases),\n",
    "                \"Report\"    : copy.deepcopy(net.training_report),\n",
    "                \"History\"   : copy.deepcopy(history_report)\n",
    "            }\n",
    "\n",
    "        history_report = net.train(training_fold, training_labels, validation_fold, validation_labels)\n",
    "\n",
    "        # scelta dei parametri per la rete che mostrano il minor errore di validazione\n",
    "        if i == 0 or net.training_report.validation_error < best_fold_params[\"Report\"].validation_error:\n",
    "            best_fold_params = {\n",
    "                \"Fold\"      : i+1,\n",
    "                \"Weights\"   : copy.deepcopy(net.weights),\n",
    "                \"Biases\"    : copy.deepcopy(net.biases),\n",
    "                \"Report\"    : copy.deepcopy(net.training_report),\n",
    "                \"History\"   : copy.deepcopy(history_report)\n",
    "            }\n",
    "\n",
    "        if constants.DEBUG_MODE:\n",
    "            break\n",
    "\n",
    "    # end for i\n",
    "\n",
    "    print(f\"\\nMiglior rete (fold): {best_fold_params['Fold']}\")\n",
    "    print(repr(best_fold_params[\"Report\"]))\n",
    "\n",
    "    # Disegno dei grafici delle curve di errore\n",
    "    auxfunc.plot_error(\n",
    "        [r.training_error for r in history_report],\n",
    "        [r.validation_error for r in history_report]\n",
    "    )\n",
    "\n",
    "    # Disegno dei grafici delle curve di accuracy\n",
    "    auxfunc.plot_accuracy(\n",
    "        [r.training_accuracy for r in history_report],\n",
    "        [r.validation_accuracy for r in history_report],\n",
    "    )\n",
    "\n",
    "    \"\"\"\n",
    "        Dopo aver individuato la configurazione di parametri (weights, biases) per cui il modello ottiene il minor errore di validazione, si riaddestra il modello sul training set completo.\n",
    "    \"\"\"\n",
    "    net.weights = copy.deepcopy(best_fold_params[\"Weights\"])\n",
    "    net.biases = copy.deepcopy(best_fold_params[\"Biases\"])\n",
    "    history_report = net.train(Xtrain, Ytrain)\n",
    "\n",
    "    # Disegno dei grafici delle curve di errore / accuracy\n",
    "    auxfunc.plot_error([r.training_error for r in history_report])\n",
    "    auxfunc.plot_accuracy([r.training_accuracy for r in history_report])\n",
    "\n",
    "    net.save_network_to_file()\n",
    "\n",
    "    return net\n",
    "\n",
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440fcec9-1f4f-47c5-83fd-5565fa93ae53",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7d92aa-1c9d-40d4-890b-ceb361fc1842",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Ytrain, Xtest, Ytest = df.loadDataset(constants.COPPIE_TRAINING, constants.COPPIE_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f866b7-7919-4de0-8bd9-e03ae36fa49b",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0917fe04-d798-47be-a3a5-6ed418f7350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nK-fold cross-validation iniziato: {datetime.now().strftime(constants.DATE_TIME_FORMAT)}\")\n",
    "start_time = time.time()\n",
    "\n",
    "net = k_fold_cross_validation(Xtrain, Ytrain)\n",
    "\n",
    "end_time = time.time()\n",
    "tot_time = end_time - start_time\n",
    "\n",
    "print(f\"\\nK-fold cross-validation completato: {datetime.now().strftime(constants.DATE_TIME_FORMAT)}\")\n",
    "print(f\"Tempo trascorso: {tot_time:.3f} secondi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a068c102",
   "metadata": {},
   "source": [
    "Se si vuole utilizzare una configurazione di parametri di una rete giÃ  addestrata con accuracy del circa 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037817ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = NeuralNetwork.load_network_from_file(constants.OUTPUT_DIRECTORY+'nn.pkl')\n",
    "# print(repr(net))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3ca79d-88eb-4fee-ac0a-d49588514371",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f832b7d8-4cc1-4831-b9b8-baa8b9978c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.test(Xtest, Ytest, plot_mode=constants.PlotTestingMode.ALL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
