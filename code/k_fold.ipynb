{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9e19b73",
   "metadata": {},
   "source": [
    "## k_fold.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea627e4-3f8d-4b0c-8510-f11be4958ea3",
   "metadata": {},
   "source": [
    "### Valutazione di modelli con grid search e random search tramite K-fold cross validation\n",
    "> Questo notebook fornisce un ambiente interattivo per l'esplorazione e l'addestramento di reti neurali per il riconoscimento delle cifre del dataset MNIST, utilizzando la libreria custom messa a disposizione dagli autori. Inoltre, fornisce un framework completo per eseguire la k-fold cross validation e la selezione degli iper-parametri.\n",
    "\n",
    "Autori:\n",
    "- Alessandro Trincone\n",
    "- Mario Gabriele Carofano"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fd3436",
   "metadata": {},
   "source": [
    "### Importazione di moduli e librerie\n",
    "> Per il corretto funzionamento del notebook, è necessario importare alcuni moduli e librerie, tra cui:\n",
    "> - la libreria `numpy` per l'utilizzo di strutture dati e funzioni matematiche efficienti;\n",
    "> - il modulo `NeuralNetwork` per costruire reti neurali tramite la libreria custom messa a disposizione dagli autori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6fb490-c50e-48dd-a7c4-a785d3966e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import auxfunc\n",
    "import constants\n",
    "from artificial_neural_network import NeuralNetwork\n",
    "from training_params import TrainingParams\n",
    "import dataset_functions as df\n",
    "import plot_functions as pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6799a2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pprint\n",
    "import time\n",
    "from datetime import datetime\n",
    "import copy\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f062f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45ca168",
   "metadata": {},
   "source": [
    "Con questo quaderno, gli utenti possono:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440fcec9-1f4f-47c5-83fd-5565fa93ae53",
   "metadata": {},
   "source": [
    "### Eseguire la K-fold cross validation\n",
    "> Questa tecnica di validazione può essere utilizzata per la selezione degli iper-parametri di addestramento come:\n",
    "> - `eta_minus` e `eta_plus`, specifici dell'algoritmo di aggiornamento dei pesi RPROP;\n",
    "> - `l_sizes`, cioè la lista delle dimensioni dei layer interni della rete neurale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6912001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(\n",
    "        out_directory : str,\n",
    "        Xtrain : list[np.ndarray],\n",
    "        Ytrain : list[np.ndarray],\n",
    "        k : int = constants.DEFAULT_K_FOLD_VALUE,\n",
    "        l_sizes : list[int] = constants.DEFAULT_LAYER_NEURONS,\n",
    "        params : TrainingParams = None\n",
    ") -> list[dict]:\n",
    "    \n",
    "    \"\"\"\n",
    "        E' una tecnica di validazione che utilizza una parte indipendente del training set per la fase di validazione. Si utilizza per la selezione degli iper-parametri che restituiscono il minor errore di validazione sull'addestramento del modello.\n",
    "\n",
    "        Parameters:\n",
    "        -   out_directory : la directory di output dove salvare i grafici della k-fold cross validation.\n",
    "        -   Xtrain : la matrice di esempi da classificare.\n",
    "        -   Ytrain : la matrice di etichette corrispondenti agli esempi (ground truth).\n",
    "        -   k : e' un numero intero che indica in quante fold dividere il training set.\n",
    "        -   l_sizes : e' una lista contenente le dimensioni di uno o piu' hidden layer e dell'output layer della rete neurale.\n",
    "        -   params : e' un oggetto della classe TrainingParams che contiene alcuni iper-parametri per la fase di addestramento della rete neurale.\n",
    "\n",
    "        Returns:\n",
    "        -   k_fold_report : una lista di metriche di valutazione relative ai valori di errore e di accuracy di validazione ottenuti durante le fasi di addestramento dei modelli sulle diverse fold.\n",
    "    \"\"\"\n",
    "\n",
    "    k_fold_report = []\n",
    "\n",
    "    Xfolds, Yfolds = df.split_dataset(Xtrain, Ytrain, k)\n",
    "\n",
    "    for i in range(k):\n",
    "\n",
    "        print(f\"\\nFold {i+1} di {k}\")\n",
    "\n",
    "        # Tutti gli altri parametri di NeuralNetwork sono inizializzati con i valori default\n",
    "        net = NeuralNetwork(l_sizes=l_sizes, t_par=params)\n",
    "\n",
    "        training_fold = np.concatenate([fold for j, fold in enumerate(Xfolds) if j != i])\n",
    "        training_labels = np.concatenate([fold for j, fold in enumerate(Yfolds) if j != i])\n",
    "        validation_fold = Xfolds[i]\n",
    "        validation_labels = Yfolds[i]\n",
    "\n",
    "        history_report = net.train(\n",
    "            training_fold, training_labels,\n",
    "            validation_fold, validation_labels\n",
    "        )\n",
    "\n",
    "        train_errs  = [r.training_error for r in history_report]\n",
    "        val_errs    = [r.validation_error for r in history_report]\n",
    "\n",
    "        train_accs  = [r.training_accuracy for r in history_report]\n",
    "        val_accs    = [r.validation_accuracy for r in history_report]\n",
    "\n",
    "        k_fold_report.append({\n",
    "            \"Fold\"          : i+1,\n",
    "            \"ET_history\"    : train_errs,\n",
    "            \"EV_history\"    : val_errs,\n",
    "            \"E_value\"       : net.training_report.validation_error,\n",
    "            \"E_min\"         : np.min(val_errs),\n",
    "            \"E_max\"         : np.max(val_errs),\n",
    "            \"AT_history\"    : train_accs,\n",
    "            \"AV_history\"    : val_accs,\n",
    "            \"A_value\"       : net.training_report.validation_accuracy,\n",
    "            \"A_min\"         : np.min(val_accs),\n",
    "            \"A_max\"         : np.max(val_accs)\n",
    "        })\n",
    "\n",
    "        net.save_network_to_file(out_directory, out_name=f\"net_Fold{i+1}.pkl\")\n",
    "\n",
    "        del net\n",
    "        del training_fold, training_labels\n",
    "        del validation_fold, validation_labels\n",
    "        gc.collect()\n",
    "\n",
    "        if constants.DEBUG_MODE:\n",
    "            break\n",
    "\n",
    "    # end for i\n",
    "    \n",
    "    return k_fold_report\n",
    "\n",
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a27525a",
   "metadata": {},
   "source": [
    "### Eseguire la grid search per il tuning degli iper-parametri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd504f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_cv() -> list[tuple[float, float, int]]:\n",
    "    \n",
    "    \"\"\"\n",
    "        Ricerca la miglior combinazione di iper-parametri in uno spazio dei parametri ben delimitato da una griglia di valori (da qui, il nome Grid Search).\n",
    "\n",
    "        Returns:\n",
    "        -   Restituisce una lista di iper-parametri (cioe': eta minus, eta plus e il numero di neuroni per l'hidden layer) campionati da uno spazio dei parametri limitato in una griglia di valori.\n",
    "    \"\"\"\n",
    "\n",
    "    # Il valore tipico per \"eta minus\" e' compreso tra 0.5 e 0.9.\n",
    "    # Valori piccoli riducono considerevolmente il passo di aggiornamento migliorando la stabilita', ma potenzialmente rallentando la convergenza. Al contrario, valori piu' grandi consentono una convergenza piu' rapida ma con il rischio di instabilita'.\n",
    "    eta_minus_values = [0.5, 0.7, 0.9]\n",
    "\n",
    "    # Il valore tipico per \"eta plus\" e' compreso tra 1.2 e 1.5.\n",
    "    # Si possono utilizzare valori piu' o meno piccoli in base alle necessita' della propria applicazione, e i vantaggi / svantaggi di questa scelta sono gli stessi di cui sopra.\n",
    "    eta_plus_values = [1.2, 1.3, 1.5]\n",
    "\n",
    "    # Per problemi di classificazione (es. riconoscimento di cifre scritte a mano), un intervallo comune per il numero di neuroni e' da 10 a 100 per uno o due hidden layer.\n",
    "    # Tuttavia, siccome l'input ha alta dimensionalita', potrebbe essere necessario aumentare il numero di neuroni per catturare le caratteristiche importanti. Ad esempio, per immagini 28x28, l'hidden layer puo' avere un numero di neuroni compreso tra 32 e 128.\n",
    "    hidden_layer_values = [32, 64, 128]\n",
    "\n",
    "    # Si restituiscono tutte le possibili combinazioni di iper-parametri in questo spazio limitato.\n",
    "    return [\n",
    "        (x, y, z)\n",
    "        for x in eta_minus_values\n",
    "        for y in eta_plus_values\n",
    "        for z in hidden_layer_values\n",
    "    ]\n",
    "\n",
    "# end\n",
    "\n",
    "# RIFERIMENTI\n",
    "# Grid Search vs. Random Search : https://www.youtube.com/watch?v=G-fXV-o9QV8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a984210",
   "metadata": {},
   "source": [
    "### Eseguire la random search per il tuning degli iper-parametri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec248997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search_cv(\n",
    "        r : int = constants.DEFAULT_RANDOM_COMBINATIONS\n",
    ") -> list[tuple[float, float, int]]:\n",
    "    \n",
    "    \"\"\"\n",
    "        Ricerca la miglior combinazione di iper-parametri campionando in modo casuale (da qui, il nome Random Search) all'interno dell'intero spazio dei parametri un numero limitato di combinazioni.\n",
    "\n",
    "        Parameters:\n",
    "        -   r : e' un numero intero che indica il numero di combinazioni di iper-parametri da campionare.\n",
    "\n",
    "        Returns:\n",
    "        -   Restituisce una lista di iper-parametri (cioe': eta minus, eta plus e il numero di neuroni per l'hidden layer) campionati in modo casuale dall'intero spazio.\n",
    "    \"\"\"\n",
    "\n",
    "    return [(\n",
    "        np.random.uniform(low=0.5, high=0.9),\n",
    "        np.random.uniform(low=1.2, high=1.5),\n",
    "        np.random.randint(low=32, high=128)\n",
    "    ) for _ in range(r)]\n",
    "\n",
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8396420f",
   "metadata": {},
   "source": [
    "### Valutare le prestazioni e le predizioni della rete neurale\n",
    "> Grazie alla libreria messa a disposizione dagli autori del notebook, è possibile addestrare e valutare le prestazioni (nonché le predizioni) della rete neurale addestrata tramite specifiche funzionalità per la visualizzazione ed il salvataggio di report nella forma di tabelle, grafici di diverso tipo e anche immagini.\n",
    "\n",
    "> In questo esempio di utilizzo:\n",
    "> - Si carica il MNIST training set e il MNIST test set in due strutture dati separate.\n",
    "> - Si memorizza in 'out_directory' la directory di output dove salvare i grafici richiesti.\n",
    "> - Si applica la Grid Search K-Fold Cross Validation separando il MNIST training set in due sottoinsiemi distinti e separati (training e validation)\n",
    "> - Si applica la Random Search K-Fold Cross Validation (applicando la suddivisione come sopra).\n",
    "> - Si addestra una nuova rete neurale sulla miglior combinazione di iper-parametri ottenuta sull'intero MNIST training set.\n",
    "> - Si verificano le predizioni della rete neurale sul MNIST test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7d92aa-1c9d-40d4-890b-ceb361fc1842",
   "metadata": {},
   "outputs": [],
   "source": [
    "idTrain, Xtrain, Ytrain, idTest, Xtest, Ytest = df.loadDataset(constants.COPPIE_TRAINING, constants.COPPIE_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a456318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_directory = constants.OUTPUT_DIRECTORY + datetime.now().strftime(constants.OUTPUT_DATE_TIME_FORMAT) + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0a1344",
   "metadata": {},
   "outputs": [],
   "source": [
    "for search_type in [\"Grid Search\", \"Random Search\"]:\n",
    "\n",
    "    print(f\"\\nValutazione con {search_type} iniziata: {datetime.now().strftime(constants.PRINT_DATE_TIME_FORMAT)}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Si inizializza un \"DataFrame\" per la raccolta delle metriche di valutazione.\n",
    "    stats = pd.DataFrame({\n",
    "        \"Eta minus\"     : [],\n",
    "        \"Eta plus\"      : [],\n",
    "        \"Hidden layer\"  : [],\n",
    "        \"Mean error\"    : [],\n",
    "        \"Std error\"     : [],\n",
    "        \"Mean accuracy\" : [],\n",
    "        \"Std accuracy\"  : [],\n",
    "        \"Elapsed time\"  : []\n",
    "    })\n",
    "\n",
    "    # Selezione delle combinazioni di iper-parametri.\n",
    "    params = grid_search_cv() if search_type == \"Grid Search\" else random_search_cv(constants.DEFAULT_RANDOM_COMBINATIONS)\n",
    "\n",
    "    # Esecuzione della cross validation per ogni combinazione di iper-parametri.\n",
    "    for i, p in enumerate(params):\n",
    "\n",
    "        # Scelta della combinazione di iper-parametri corrente.\n",
    "        em = p[0]\n",
    "        ep = p[1]\n",
    "        hl = p[2]\n",
    "\n",
    "        print(f\"\\nCombinazione {i}:\\n\\tEta minus = {em},\\n\\tEta plus = {ep},\\n\\tHidden layer = {int(hl)}\\n\")\n",
    "        k_fold_out = f\"{out_directory}{search_type.replace(' ', '_').lower()}/\"\n",
    "\n",
    "        # Si applica la tecnica di validazione \"K-fold cross validation\" per valutare la combinazione di iper-parametri corrente.\n",
    "        k_fold_report = k_fold_cross_validation(\n",
    "            k_fold_out + f\"comb_{i}/\",\n",
    "            Xtrain, Ytrain, constants.DEFAULT_K_FOLD_VALUE,\n",
    "            [hl, 10],\n",
    "            params=TrainingParams(\n",
    "                eta_minus=em,\n",
    "                eta_plus=ep\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Si recuperano tutti i valori di errore e accuracy di validazione della fase di addestramento.\n",
    "        fold_errs = [r['E_value'] for r in k_fold_report]\n",
    "        fold_accs = [r['A_value'] for r in k_fold_report]\n",
    "\n",
    "        end_time = time.time()\n",
    "        tot_time = end_time - start_time\n",
    "\n",
    "        # Si crea un dizionario per raccogliere tutte le metriche di valutazione riguardo la rete appena addestrata sulla combinazione di iper-parametri corrente.\n",
    "        new_row = {\n",
    "            \"Eta minus\"     : em,\n",
    "            \"Eta plus\"      : ep,\n",
    "            \"Hidden layer\"  : hl,\n",
    "            \"Mean error\"    : np.mean(fold_errs),\n",
    "            \"Std error\"     : np.std(fold_errs),\n",
    "            \"Mean accuracy\" : np.mean(fold_accs),\n",
    "            \"Std accuracy\"  : np.std(fold_accs),\n",
    "            \"Elapsed time\"  : tot_time / 3600.0\n",
    "        }\n",
    "\n",
    "        # Si aggiunge il dizionario come nuova riga alla tabella generale.\n",
    "        stats = pd.concat([stats, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "        # Si ripristina l'indice per mantenere l'ordinamento cronologico.\n",
    "        stats = stats.reset_index(drop=True)\n",
    "\n",
    "        # Si disegna un'immagine contenente i risultati dell'esecuzione della K-fold.\n",
    "        pf.plot_search_report(k_fold_out + f\"comb_{i}/\", search_type, k_fold_report, stats.iloc[-1])\n",
    "\n",
    "        # Visualizzazione del tempo impiegato per la valutazione di una singola combinazione\n",
    "        print(f\"\\nValutazione della combinazione {i} completata: {datetime.now().strftime(constants.PRINT_DATE_TIME_FORMAT)}\")\n",
    "        print(f\"Tempo trascorso: {tot_time:.3f} secondi\")\n",
    "\n",
    "    # end for i\n",
    "\n",
    "    # Si ordina il DataFrame in modo non decrescente per i valori della colonna 'Mean Error'.\n",
    "    stats = stats.sort_values(by=['Mean error'])\n",
    "    formatted_stats = stats.style.format({\n",
    "        \"Eta minus\"     : '{:.5f}',\n",
    "        \"Eta plus\"      : '{:.5f}',\n",
    "        \"Hidden layer\"  : '{:.0f}',\n",
    "        \"Mean error\"    : '{:.5f}',\n",
    "        \"Std error\"     : '{:.5f}',\n",
    "        \"Mean accuracy\" : '{:.2%}',\n",
    "        \"Std accuracy\"  : '{:.2%}',\n",
    "        \"Elapsed time\"  : '{:.5f}'\n",
    "    })\n",
    "\n",
    "    # Si visualizzano le statistiche raccolte in una tabella.\n",
    "    display(formatted_stats)\n",
    "\n",
    "    # Si salva il contenuto della tabella in un file .csv.\n",
    "    os.makedirs(out_directory, exist_ok=True)\n",
    "    formatted_stats.to_string(k_fold_out + 'stats.csv', delimiter=',')\n",
    "\n",
    "    # Visualizzazione della miglior combinazione di iper-parametri.\n",
    "    best_params_idx = stats['Mean error'].idxmin()\n",
    "    print(f\"\\nMiglior combinazione:\\n\\tIndex = {best_params_idx},\\n\\tEta minus = {stats['Eta minus'][best_params_idx]:.5f},\\n\\tEta plus = {stats['Eta plus'][best_params_idx]:.5f},\\n\\tHidden layer = {stats['Hidden layer'][best_params_idx]:.0f}\\n\")\n",
    "\n",
    "    # Visualizzazione del tempo impiegato per l'intera fase di valutazione.\n",
    "    end_time = time.time()\n",
    "    tot_time = end_time - start_time\n",
    "\n",
    "    print(f\"\\nValutazione con {search_type} completata: {datetime.now().strftime(constants.PRINT_DATE_TIME_FORMAT)}\")\n",
    "    print(f\"Tempo trascorso: {tot_time:.3f} secondi\")\n",
    "\n",
    "# RIFERIMENTI\n",
    "# https://saturncloud.io/blog/how-to-insert-a-row-to-pandas-dataframe/\n",
    "# https://www.geeksforgeeks.org/display-the-pandas-dataframe-in-table-style/\n",
    "# https://stackoverflow.com/questions/75956209/error-dataframe-object-has-no-attribute-append\n",
    "# https://stackoverflow.com/questions/17006641/single-line-nested-for-loops\n",
    "# https://stackoverflow.com/questions/20937538/how-to-display-pandas-dataframe-of-floats-using-a-format-string-for-columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6778a781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recupero dei migliori iper-parametri tra grid search e random search.\n",
    "# net_file = NeuralNetwork.load_network_from_file(\"...\")\n",
    "# print(net_file)\n",
    "# ...\n",
    "\n",
    "# Addestramento di una nuova rete neurale su questi iper-parametri.\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f832b7d8-4cc1-4831-b9b8-baa8b9978c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica delle prestazioni della rete neurale sul MNIST test set\n",
    "# Salvataggio delle immagini / grafici sulle predizioni.\n",
    "# net.test(\n",
    "#     out_directory,\n",
    "#     idTest, Xtest, Ytest,\n",
    "#     plot_mode=constants.PlotTestingMode.ALL\n",
    "# )\n",
    "\n",
    "# net.predict(idTest, Xtest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
