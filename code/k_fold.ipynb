{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9e19b73",
   "metadata": {},
   "source": [
    "## k_fold.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea627e4-3f8d-4b0c-8510-f11be4958ea3",
   "metadata": {},
   "source": [
    "### Valutazione di modelli con grid search e random search tramite K-fold cross validation\n",
    "> Questo notebook fornisce un ambiente interattivo per l'esplorazione e l'addestramento di reti neurali per il riconoscimento delle cifre del dataset MNIST, utilizzando la libreria custom messa a disposizione dagli autori. Inoltre, fornisce un framework completo per eseguire la k-fold cross validation e la selezione degli iperparametri,\n",
    "\n",
    "Autori:\n",
    "- Alessandro Trincone\n",
    "- Mario Gabriele Carofano"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fd3436",
   "metadata": {},
   "source": [
    "### Importazione di moduli e librerie\n",
    "> Per il corretto funzionamento del notebook, è necessario importare alcuni moduli e librerie, tra cui:\n",
    "> - la libreria `numpy` per l'utilizzo di strutture dati e funzioni matematiche efficienti;\n",
    "> - il modulo `NeuralNetwork` per costruire reti neurali tramite la libreria custom messa a disposizione dagli autori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6fb490-c50e-48dd-a7c4-a785d3966e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import auxfunc\n",
    "import constants\n",
    "from artificial_neural_network import NeuralNetwork\n",
    "from training_report import TrainingReport\n",
    "from training_params import TrainingParams\n",
    "import dataset_functions as df\n",
    "import plot_functions as pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6799a2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pprint\n",
    "import time\n",
    "from datetime import datetime\n",
    "import copy\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f062f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45ca168",
   "metadata": {},
   "source": [
    "Con questo quaderno, gli utenti possono:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440fcec9-1f4f-47c5-83fd-5565fa93ae53",
   "metadata": {},
   "source": [
    "### Eseguire la K-fold cross validation\n",
    "> Questa tecnica di validazione può essere utilizzata per la selezione degli iper-parametri di addestramento come:\n",
    "> - `eta_minus` e `eta_plus`, specifici dell'algoritmo di aggiornamento dei pesi RPROP;\n",
    "> - `l_sizes`, cioè la lista delle dimensioni dei layer interni della rete neurale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6912001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(\n",
    "        out_directory : str,\n",
    "        Xtrain : list[np.ndarray],\n",
    "        Ytrain : list[np.ndarray],\n",
    "        k : int = constants.DEFAULT_K_FOLD_VALUE,\n",
    "        l_sizes : list[int] = constants.DEFAULT_HIDDEN_LAYER_NEURONS,\n",
    "        params : TrainingParams = None\n",
    ") -> list[dict]:\n",
    "    \n",
    "    \"\"\"\n",
    "        E' una tecnica di validazione che utilizza una parte indipendente del training set per la fase di validazione. Si utilizza per la selezione degli iper-parametri che restituiscono il minor errore di validazione sull'addestramento del modello.\n",
    "\n",
    "        Parameters:\n",
    "        -   out_directory : la directory di output dove salvare i grafici della k-fold cross validation.\n",
    "        -   Xtrain : la matrice di esempi da classificare.\n",
    "        -   Ytrain : la matrice di etichette corrispondenti agli esempi (ground truth).\n",
    "        -   k : e' un numero intero che indica in quante fold dividere il training set.\n",
    "        -   l_sizes : e' una lista contenente le dimensioni di uno o piu' hidden layer e dell'output layer della rete neurale.\n",
    "        -   params : e' un oggetto della classe TrainingParams che contiene alcuni iperparametri per la fase di addestramento della rete neurale.\n",
    "\n",
    "        Returns:\n",
    "        -   k_fold_report : una lista di metriche di valutazione relative ai valori di errore e di accuracy di validazione ottenuti durante le fasi di addestramento dei modelli sulle diverse fold.\n",
    "    \"\"\"\n",
    "\n",
    "    k_fold_report = []\n",
    "\n",
    "    Xfolds, Yfolds = df.split_dataset(Xtrain, Ytrain, k)\n",
    "\n",
    "    for i in range(k):\n",
    "\n",
    "        print(f\"\\nFold {i+1} di {k}\")\n",
    "\n",
    "        # Tutti gli altri parametri di NeuralNetwork sono inizializzati con i valori default\n",
    "        net = NeuralNetwork(l_sizes=l_sizes)\n",
    "\n",
    "        training_fold = np.concatenate([fold for j, fold in enumerate(Xfolds) if j != i])\n",
    "        training_labels = np.concatenate([fold for j, fold in enumerate(Yfolds) if j != i])\n",
    "        validation_fold = Xfolds[i]\n",
    "        validation_labels = Yfolds[i]\n",
    "\n",
    "        history_report = net.train(\n",
    "            training_fold, training_labels,\n",
    "            validation_fold, validation_labels,\n",
    "            params\n",
    "        )\n",
    "\n",
    "        train_errs = [r.validation_error for r in history_report]\n",
    "        train_accs = [r.validation_accuracy for r in history_report]\n",
    "\n",
    "        k_fold_report.append({\n",
    "            \"Fold\"      : i+1,\n",
    "            \"E_value\"   : net.training_report.validation_error,\n",
    "            \"E_min\"     : np.min(train_errs),\n",
    "            \"E_max\"     : np.max(train_errs),\n",
    "            \"A_value\"   : net.training_report.validation_accuracy,\n",
    "            \"A_min\"     : np.min(train_accs),\n",
    "            \"A_max\"     : np.max(train_accs)\n",
    "        })\n",
    "\n",
    "        del net\n",
    "        del training_fold, training_labels\n",
    "        del validation_fold, validation_labels\n",
    "        gc.collect()\n",
    "\n",
    "        if constants.DEBUG_MODE:\n",
    "            break\n",
    "\n",
    "    # end for i\n",
    "    \n",
    "    return k_fold_report\n",
    "\n",
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a27525a",
   "metadata": {},
   "source": [
    "### Eseguire la grid search per il tuning degli iper-parametri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd504f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_cv(\n",
    "        out_directory : str,\n",
    "        Xtrain : list[np.ndarray],\n",
    "        Ytrain : list[np.ndarray],\n",
    "        k : int = constants.DEFAULT_K_FOLD_VALUE,\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    \"\"\"\n",
    "        Ricerca la miglior combinazione di iper-parametri in uno spazio dei parametri ben delimitato da una griglia di valori (da qui, il nome Grid Search) addestrando una nuova rete neurale per ogni possibile combinazione di tale griglia.\n",
    "\n",
    "        Parameters:\n",
    "        -   out_directory : la directory di output dove salvare i grafici della k-fold cross validation.\n",
    "        -   Xtrain : la matrice di esempi da classificare.\n",
    "        -   Ytrain : la matrice di etichette corrispondenti agli esempi (ground truth).\n",
    "        -   k : e' un numero intero che indica in quante fold dividere il training set.\n",
    "\n",
    "        Returns:\n",
    "        -   Restituisce un pandas.Dataframe contenente tutte le combinazioni di iper-parametri che sono stati verificati da quest'operazione di ricerca e le rispettive metriche di valutazione. \n",
    "    \"\"\"\n",
    "\n",
    "    # Il valore tipico per \"eta minus\" e' compreso tra 0.5 e 0.9.\n",
    "    # Valori più vicini a 0.5 riducono il passo di aggiornamento in modo più aggressivo, migliorando la stabilita', ma potenzialmente rallentando la convergenza.\n",
    "    # Valori più vicini a 0.9 sono meno aggressivi, permettendo una convergenza più rapida ma con il rischio di instabilita'.\n",
    "    eta_minus_values = [0.5, 0.7, 0.9]\n",
    "\n",
    "    # Il valore tipico per \"eta plus\" e' compreso tra 1.2 e 1.5.\n",
    "    # Valori più vicini a 1.2 incrementano il passo di aggiornamento in modo più moderato, migliorando la stabilita' e riducendo il rischio di oscillazioni.\n",
    "    # Valori più vicini a 1.5 incrementano il passo di aggiornamento in modo più aggressivo, accelerando la convergenza ma aumentando il rischio di instabilita'.\n",
    "    eta_plus_values = [1.2, 1.3, 1.5]\n",
    "\n",
    "    # Per problemi di classificazione (es. riconoscimento di cifre scritte a mano), un intervallo comune per il numero di neuroni è da 10 a 100 per uno o due hidden layer.\n",
    "    # Tuttavia, siccome l'input ha alta dimensionalita', potrebbe essere necessario aumentare il numero di neuroni per catturare le caratteristiche importanti. Ad esempio, per immagini 28x28, l'hidden layer puo' avere un numero di neuroni compreso tra 128 e 512.\n",
    "    hidden_layer_values = [128, 256, 512]\n",
    "\n",
    "    # Si inizializza un \"DataFrame\" per la raccolta delle metriche di valutazione.\n",
    "    stats = pd.DataFrame({\n",
    "        \"Eta minus\"     : [],\n",
    "        \"Eta plus\"      : [],\n",
    "        \"Hidden layer\"  : [],\n",
    "        \"Mean error\"    : [],\n",
    "        \"Std error\"     : [],\n",
    "        \"Mean accuracy\" : [],\n",
    "        \"Std accuracy\"  : []\n",
    "    })\n",
    "\n",
    "    # Si calcolano tutte le possibili combinazioni di iper-parametri.\n",
    "    combs = [\n",
    "        (x, y, z)\n",
    "        for x in eta_minus_values\n",
    "        for y in eta_plus_values\n",
    "        for z in hidden_layer_values\n",
    "    ]\n",
    "\n",
    "    # Questo ciclo \"for\" esamina tutte le possibili combinazioni di iper-parametri.\n",
    "    for i, (em, ep, hl) in enumerate(combs):\n",
    "\n",
    "        print(f\"\\nCombinazione {i+1}:\\n\\tEta minus = {em},\\n\\tEta plus = {ep},\\n\\tHidden layer = {hl}\\n\")\n",
    "\n",
    "        # Si applica la tecnica di validazione \"K-fold cross validation\" per valutare la combinazione di iper-parametri corrente.\n",
    "        k_fold_report = k_fold_cross_validation(\n",
    "            out_directory,\n",
    "            Xtrain, Ytrain, k,\n",
    "            [hl, 10],\n",
    "            params=TrainingParams(\n",
    "                eta_minus=em,\n",
    "                eta_plus=ep\n",
    "            )\n",
    "        )\n",
    "\n",
    "        fold_errs = [r['E_value'] for r in k_fold_report]\n",
    "        fold_accs = [r['A_value'] for r in k_fold_report]\n",
    "\n",
    "        # Si crea un dizionario per raccogliere tutte le metriche di valutazione riguardo la rete appena addestrata sulla combinazione di iperparametri corrente.\n",
    "        new_row = {\n",
    "            \"Eta minus\"     : em,\n",
    "            \"Eta plus\"      : ep,\n",
    "            \"Hidden layer\"  : hl,\n",
    "            \"Mean error\"    : np.mean(fold_errs),\n",
    "            \"Std error\"     : np.std(fold_errs),\n",
    "            \"Mean accuracy\" : np.mean(fold_accs),\n",
    "            \"Std accuracy\"  : np.std(fold_accs)\n",
    "        }\n",
    "\n",
    "        # Si aggiunge il dizionario come nuova riga alla tabella generale.\n",
    "        stats = pd.concat([stats, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "        # Si ripristina l'indice per mantenere l'ordinamento cronologico.\n",
    "        stats = stats.reset_index(drop=True)\n",
    "\n",
    "        pf.plot_search_report(out_directory, \"Grid Search\", k_fold_report, stats.iloc[-1])\n",
    "    \n",
    "    # end for i, (em, ep, hl)\n",
    "\n",
    "    # Si ordina il DataFrame in modo non decrescente per i valori della colonna 'Mean Error'.\n",
    "    stats = stats.sort_values(by=['Mean error'])\n",
    "\n",
    "    formatted_stats = stats.style.format({\n",
    "        \"Eta minus\"     : '{:.5f}',\n",
    "        \"Eta plus\"      : '{:.5f}',\n",
    "        \"Hidden layer\"  : '{:.0f}',\n",
    "        \"Mean error\"    : '{:.5f}',\n",
    "        \"Std error\"     : '{:.5f}',\n",
    "        \"Mean accuracy\" : '{:.2%}',\n",
    "        \"Std accuracy\"  : '{:.2%}'\n",
    "    })\n",
    "    \n",
    "    # Si visualizzano le statistiche raccolte in una tabella.\n",
    "    display(formatted_stats)\n",
    "\n",
    "    # Si salva il contenuto della tabella in un file .csv.\n",
    "    os.makedirs(out_directory, exist_ok=True)\n",
    "    formatted_stats.to_string(out_directory + 'grid_search_stats.csv', delimiter=',')\n",
    "\n",
    "    return stats\n",
    "\n",
    "# end\n",
    "\n",
    "# RIFERIMENTI\n",
    "# Grid Search vs. Random Search : https://www.youtube.com/watch?v=G-fXV-o9QV8\n",
    "# https://saturncloud.io/blog/how-to-insert-a-row-to-pandas-dataframe/\n",
    "# https://www.geeksforgeeks.org/display-the-pandas-dataframe-in-table-style/\n",
    "# https://stackoverflow.com/questions/75956209/error-dataframe-object-has-no-attribute-append\n",
    "# https://stackoverflow.com/questions/17006641/single-line-nested-for-loops\n",
    "# https://stackoverflow.com/questions/20937538/how-to-display-pandas-dataframe-of-floats-using-a-format-string-for-columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a984210",
   "metadata": {},
   "source": [
    "### Eseguire la random search per il tuning degli iper-parametri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4281dd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search_cv(\n",
    "        out_directory : str,\n",
    "        Xtrain : list[np.ndarray],\n",
    "        Ytrain : list[np.ndarray],\n",
    "        k : int = constants.DEFAULT_K_FOLD_VALUE,\n",
    "        r : int = constants.DEFAULT_RANDOM_COMBINATIONS\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    \"\"\"\n",
    "        Ricerca la miglior combinazione di iper-parametri campionando in modo casuale (da qui, il nome Random Search) all'interno dell'intero spazio dei parametri un numero limitato di combinazioni. Quindi, per ognuna di queste combinazioni addestra una nuova rete neurale.\n",
    "\n",
    "        Parameters:\n",
    "        -   out_directory : la directory di output dove salvare i grafici della k-fold cross validation.\n",
    "        -   Xtrain : la matrice di esempi da classificare.\n",
    "        -   Ytrain : la matrice di etichette corrispondenti agli esempi (ground truth).\n",
    "        -   k : e' un numero intero che indica in quante fold dividere il training set.\n",
    "        -   r : e' un numero intero che indica il numero di combinazioni di iperparametri da testare.\n",
    "\n",
    "        Returns:\n",
    "        -   Restituisce un pandas.Dataframe contenente tutte le combinazioni di iper-parametri che sono stati verificati da quest'operazione di ricerca e le rispettive metriche di valutazione.\n",
    "    \"\"\"\n",
    "\n",
    "    stats = pd.DataFrame({\n",
    "        \"Eta minus\"     : [],\n",
    "        \"Eta plus\"      : [],\n",
    "        \"Hidden layer\"  : [],\n",
    "        \"Mean error\"    : [],\n",
    "        \"Std error\"     : [],\n",
    "        \"Mean accuracy\" : [],\n",
    "        \"Std accuracy\"  : []\n",
    "    })\n",
    "\n",
    "    # Questo ciclo \"for\" verifica solo \"r\" combinazioni di iper-parametri.\n",
    "    for i in range(r):\n",
    "\n",
    "        em = np.random.uniform(low=0.5, high=0.9)\n",
    "        ep = np.random.uniform(low=1.2, high=1.5)\n",
    "        hl = np.random.randint(low=128, high=512)\n",
    "        \n",
    "        print(f\"\\nCombinazione {i+1}:\\n\\tEta minus = {em},\\n\\tEta plus = {ep},\\n\\tHidden layer = {int(hl)}\\n\")\n",
    "\n",
    "        k_fold_report = k_fold_cross_validation(\n",
    "            out_directory,\n",
    "            Xtrain, Ytrain, k,\n",
    "            [hl, 10],\n",
    "            params=TrainingParams(\n",
    "                eta_minus=em,\n",
    "                eta_plus=ep\n",
    "            )\n",
    "        )\n",
    "\n",
    "        fold_errs = [r['E_value'] for r in k_fold_report]\n",
    "        fold_accs = [r['A_value'] for r in k_fold_report]\n",
    "\n",
    "        new_row = {\n",
    "            \"Eta minus\"     : em,\n",
    "            \"Eta plus\"      : ep,\n",
    "            \"Hidden layer\"  : hl,\n",
    "            \"Mean error\"    : np.mean(fold_errs),\n",
    "            \"Std error\"     : np.std(fold_errs),\n",
    "            \"Mean accuracy\" : np.mean(fold_accs),\n",
    "            \"Std accuracy\"  : np.std(fold_accs)\n",
    "        }\n",
    "\n",
    "        stats = pd.concat([stats, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        stats = stats.reset_index(drop=True)\n",
    "\n",
    "        pf.plot_search_report(out_directory, \"Random Search\", k_fold_report, stats.iloc[-1])\n",
    "\n",
    "    # end for i\n",
    "\n",
    "    stats = stats.sort_values(by=['Mean error'])\n",
    "    formatted_stats = stats.style.format({\n",
    "        \"Eta minus\"     : '{:.5f}',\n",
    "        \"Eta plus\"      : '{:.5f}',\n",
    "        \"Hidden layer\"  : '{:.0f}',\n",
    "        \"Mean error\"    : '{:.5f}',\n",
    "        \"Std error\"     : '{:.5f}',\n",
    "        \"Mean accuracy\" : '{:.2%}',\n",
    "        \"Std accuracy\"  : '{:.2%}'\n",
    "    })\n",
    "    \n",
    "    display(formatted_stats)\n",
    "\n",
    "    os.makedirs(out_directory, exist_ok=True)\n",
    "    formatted_stats.to_string(out_directory + 'random_search_stats.csv', delimiter=',')\n",
    "\n",
    "    return stats\n",
    "\n",
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8396420f",
   "metadata": {},
   "source": [
    "### Valutare le prestazioni e le predizioni della rete neurale\n",
    "> Grazie alla libreria messa a disposizione dagli autori del notebook, è possibile addestrare e valutare le prestazioni (nonché le predizioni) della rete neurale addestrata tramite specifiche funzionalità per la visualizzazione ed il salvataggio di report nella forma di tabelle, grafici di diverso tipo e anche immagini.\n",
    "\n",
    "> In questo esempio di utilizzo:\n",
    "> - Si carica il MNIST training set e il MNIST test set in due strutture dati separate.\n",
    "> - Si memorizza in 'out_directory' la directory di output dove salvare i grafici richiesti.\n",
    "> - Si applica la Grid Search K-Fold Cross Validation separando il MNIST training set in due sottoinsiemi distinti e separati (training e validation)\n",
    "> - Si applica la Random Search K-Fold Cross Validation (applicando la suddivisione come sopra).\n",
    "> - Si addestra una nuova rete neurale sulla miglior combinazione di iperparametri ottenuta sull'intero MNIST training set.\n",
    "> - Si verificano le predizioni della rete neurale sul MNIST test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7d92aa-1c9d-40d4-890b-ceb361fc1842",
   "metadata": {},
   "outputs": [],
   "source": [
    "idTrain, Xtrain, Ytrain, idTest, Xtest, Ytest = df.loadDataset(constants.COPPIE_TRAINING, constants.COPPIE_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a456318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_directory = constants.OUTPUT_DIRECTORY + datetime.now().strftime(constants.OUTPUT_DATE_TIME_FORMAT) + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0917fe04-d798-47be-a3a5-6ed418f7350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nValutazione con grid search iniziata: {datetime.now().strftime(constants.PRINT_DATE_TIME_FORMAT)}\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Esecuzione della grid search.\n",
    "grid_stats = grid_search_cv(out_directory, Xtrain, Ytrain)\n",
    "grid_best_params_idx = grid_stats['Mean error'].idxmin()\n",
    "\n",
    "# Visualizzazione della miglior combinazione di iper-parametri.\n",
    "print(f\"\\nMiglior combinazione:\\n\\tIndex = {grid_best_params_idx},\\n\\tEta minus = {grid_stats['Eta minus'][grid_best_params_idx]:.5f},\\n\\tEta plus = {grid_stats['Eta plus'][grid_best_params_idx]:.5f},\\n\\tHidden layer = {grid_stats['Hidden layer'][grid_best_params_idx]:.0f}\\n\")\n",
    "\n",
    "# Visualizzazione del tempo impiegato.\n",
    "end_time = time.time()\n",
    "tot_time = end_time - start_time\n",
    "\n",
    "print(f\"\\nValutazione con grid search completata: {datetime.now().strftime(constants.PRINT_DATE_TIME_FORMAT)}\")\n",
    "print(f\"Tempo trascorso: {tot_time:.3f} secondi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febfa306",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nValutazione con random search iniziata: {datetime.now().strftime(constants.PRINT_DATE_TIME_FORMAT)}\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Esecuzione della random search.\n",
    "random_stats = random_search_cv(out_directory, Xtrain, Ytrain)\n",
    "random_best_params_idx = random_stats['Mean error'].idxmin()\n",
    "\n",
    "# Visualizzazione della miglior combinazione di iper-parametri.\n",
    "print(f\"\\nMiglior combinazione:\\n\\tIndex = {random_best_params_idx},\\n\\tEta minus = {random_stats['Eta minus'][random_best_params_idx]:.5f},\\n\\tEta plus = {random_stats['Eta plus'][random_best_params_idx]:.5f},\\n\\tHidden layer = {random_stats['Hidden layer'][random_best_params_idx]:.0f}\\n\")\n",
    "\n",
    "# Visualizzazione del tempo impiegato.\n",
    "end_time = time.time()\n",
    "tot_time = end_time - start_time\n",
    "\n",
    "print(f\"\\nValutazione con random search completata: {datetime.now().strftime(constants.PRINT_DATE_TIME_FORMAT)}\")\n",
    "print(f\"Tempo trascorso: {tot_time:.3f} secondi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6778a781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recupero dei migliori iper-parametri tra grid search e random search.\n",
    "# ...\n",
    "\n",
    "# Addestramento di una nuova rete neurale su questi iper-parametri.\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f832b7d8-4cc1-4831-b9b8-baa8b9978c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica delle prestazioni della rete neurale sul MNIST test set\n",
    "# Salvataggio delle immagini / grafici sulle predizioni.\n",
    "# net.test(\n",
    "#     out_directory,\n",
    "#     idTest, Xtest, Ytest,\n",
    "#     plot_mode=constants.PlotTestingMode.ALL\n",
    "# )\n",
    "\n",
    "# net.predict(idTest, Xtest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
